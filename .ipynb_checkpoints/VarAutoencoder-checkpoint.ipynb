{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eda75ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU, Activation, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.layers import Reshape, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078b0ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e3fe271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f93a64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Input(shape=(28,28,1))\n",
    "Latent_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272f7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating encoder\n",
    "x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(img)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "shape_bfal = x.shape[1:]\n",
    "x = Flatten()(x)\n",
    "\n",
    "mu = Dense(Latent_size, name='mu')(x)\n",
    "log_var = Dense(Latent_size, name='log_var')(x)\n",
    "\n",
    "encoder_z = Model(img, (mu, log_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96740f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "print(shape_bfal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa3205ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 28, 28, 32)   320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 28, 28, 32)  128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 28, 28, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 14, 14, 64)   18496       ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14, 14, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 14, 14, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 7, 7, 64)     36928       ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 7, 7, 64)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3136)         0           ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 2)            6274        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " log_var (Dense)                (None, 2)            6274        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 68,932\n",
      "Trainable params: 68,612\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_z.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bc1afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    mu, log_var = args\n",
    "    epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\n",
    "    return mu + K.exp(log_var/2)*epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d067b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = Lambda(sampling, name='encoder_output')([mu, log_var])\n",
    "encoder = Model(img, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f9e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating decoder\n",
    "decoder_input = Input(shape=(Latent_size), name='decoder_input')\n",
    "x = Dense(np.prod(shape_bfal))(decoder_input)\n",
    "x = Reshape(shape_bfal)(x)\n",
    "\n",
    "x = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same')(x)\n",
    "x = Activation('sigmoid')(x)\n",
    "\n",
    "decoder_output = x\n",
    "decoder = Model(inputs=decoder_input, outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f87cda0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 28, 28, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea266dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3136)              9408      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,089\n",
      "Trainable params: 65,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de772cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "varAE = Model(inputs=img, outputs=decoder(encoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06d71d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating loss functions\n",
    "def vae_r_loss(y_true,y_pred):\n",
    "    r_loss = K.mean(K.square(y_true-y_pred), axis=1)\n",
    "    return r_loss\n",
    "\n",
    "def vae_kl_loss(y_true, y_pred):\n",
    "    kl_loss = -0.5*K.sum(1 + log_var - K.square(mu) - K.exp(log_var),axis=1)\n",
    "    return kl_loss\n",
    "\n",
    "def vae_loss(y_true, y_pred):\n",
    "    r_loss = vae_r_loss(y_true, y_pred)\n",
    "    kl_loss = vae_kl_loss(y_true, y_pred)\n",
    "    return r_loss + kl_loss\n",
    "\n",
    "varAE.compile(optimizer='adam', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "007cf49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing a custom loss is now a headache\n",
    "# class Custom_CE_Loss(loss):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         r_loss = vae_r_loss(y_true, y_pred)\n",
    "#         kl_loss = vae_kl_loss(y_true, y_pred)\n",
    "#         return r_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "521f6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b45df9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Calling `Model.fit` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.fit` with eager mode enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvarAE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\GenMo\\generative\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\GenMo\\generative\\Lib\\site-packages\\keras\\utils\\version_utils.py:126\u001b[0m, in \u001b[0;36mdisallow_legacy_graph\u001b[1;34m(cls_name, method_name)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m    119\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in graph mode is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported when the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instance was constructed with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager mode enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m     )\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Calling `Model.fit` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.fit` with eager mode enabled."
     ]
    }
   ],
   "source": [
    "varAE.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5502058b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative",
   "language": "python",
   "name": "generative"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
